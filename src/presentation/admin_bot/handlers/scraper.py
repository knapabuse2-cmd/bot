"""
Scraper handlers for admin bot.

Handles target collection from Telegram channels/chats.
"""

import asyncio
from uuid import UUID
from typing import Optional

from aiogram import Router, F
from aiogram.types import Message, CallbackQuery
from aiogram.fsm.context import FSMContext
from sqlalchemy.ext.asyncio import AsyncSession

import structlog

from src.domain.entities import (
    Account,
    AccountStatus,
    ScrapeTask,
    ScrapeTaskStatus,
    UserTarget,
    TargetStatus,
)
from src.application.services import ScraperService, ParallelScraperService, create_targets_from_usernames
from src.infrastructure.database.repositories import (
    PostgresAccountRepository,
    PostgresCampaignRepository,
    PostgresUserTargetRepository,
)

from ..states import ScraperStates
from ..keyboards import (
    get_main_menu_kb,
    get_cancel_kb,
    get_scraper_menu_kb,
    get_scraper_accounts_kb,
    get_scraper_accounts_multi_kb,
    get_scraper_campaign_select_kb,
    get_scraper_progress_kb,
    get_scraper_result_kb,
)

logger = structlog.get_logger(__name__)
router = Router(name="scraper")

# Store active scraper tasks (in-memory, for simplicity)
_active_scrapers: dict[int, ScraperService] = {}  # user_id -> scraper
_active_parallel_scrapers: dict[int, ParallelScraperService] = {}  # user_id -> parallel scraper
_active_tasks: dict[int, ScrapeTask] = {}  # user_id -> task


# =============================================================================
# Menu
# =============================================================================

@router.message(F.text == "üîç –ü–∞—Ä—Å–µ—Ä")
async def scraper_menu(message: Message) -> None:
    """Show scraper menu."""
    await message.answer(
        "üîç <b>–ü–∞—Ä—Å–µ—Ä —Ç–∞—Ä–≥–µ—Ç–æ–≤</b>\n\n"
        "–°–æ–±–µ—Ä–∏—Ç–µ username –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏–∑ –∫–∞–Ω–∞–ª–æ–≤ –∏ —á–∞—Ç–æ–≤.\n\n"
        "–ë–æ—Ç –∑–∞–π–¥—ë—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã, —Å–æ–±–µ—Ä—ë—Ç username –≤—Å–µ—Ö, "
        "–∫—Ç–æ –ø–∏—Å–∞–ª —Å–æ–æ–±—â–µ–Ω–∏—è –∏–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –∏ –¥–æ–±–∞–≤–∏—Ç –∏—Ö –∫–∞–∫ —Ç–∞—Ä–≥–µ—Ç—ã.",
        reply_markup=get_scraper_menu_kb(),
    )


@router.callback_query(F.data == "scraper:menu")
async def scraper_menu_callback(callback: CallbackQuery) -> None:
    """Show scraper menu (callback)."""
    await callback.message.edit_text(
        "üîç <b>–ü–∞—Ä—Å–µ—Ä —Ç–∞—Ä–≥–µ—Ç–æ–≤</b>\n\n"
        "–°–æ–±–µ—Ä–∏—Ç–µ username –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏–∑ –∫–∞–Ω–∞–ª–æ–≤ –∏ —á–∞—Ç–æ–≤.\n\n"
        "–ë–æ—Ç –∑–∞–π–¥—ë—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã, —Å–æ–±–µ—Ä—ë—Ç username –≤—Å–µ—Ö, "
        "–∫—Ç–æ –ø–∏—Å–∞–ª —Å–æ–æ–±—â–µ–Ω–∏—è –∏–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –∏ –¥–æ–±–∞–≤–∏—Ç –∏—Ö –∫–∞–∫ —Ç–∞—Ä–≥–µ—Ç—ã.",
        reply_markup=get_scraper_menu_kb(),
    )
    await callback.answer()


# =============================================================================
# Start Scraping Flow
# =============================================================================

@router.callback_query(F.data == "scraper:start")
async def start_scraping(
    callback: CallbackQuery,
    state: FSMContext,
    session: AsyncSession,
) -> None:
    """Start scraping flow - select account."""
    account_repo = PostgresAccountRepository(session)

    # Get accounts that can be used for scraping (ready or paused, not active in campaigns)
    all_accounts = await account_repo.list_all(limit=100)

    # Filter: prefer ready/paused accounts, also allow active if needed
    accounts = [
        a for a in all_accounts
        if a.status in (AccountStatus.READY, AccountStatus.PAUSED, AccountStatus.ACTIVE)
        and a.session_data  # Must have session
    ]

    if not accounts:
        await callback.message.edit_text(
            "‚ùå <b>–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤</b>\n\n"
            "–î–æ–±–∞–≤—å—Ç–µ –∞–∫–∫–∞—É–Ω—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤ —Ä–∞–∑–¥–µ–ª–µ üì± –ê–∫–∫–∞—É–Ω—Ç—ã.",
            reply_markup=get_scraper_menu_kb(),
        )
        await callback.answer()
        return

    await state.set_state(ScraperStates.selecting_account)

    await callback.message.edit_text(
        "üì± <b>–í—ã–±–µ—Ä–∏—Ç–µ –∞–∫–∫–∞—É–Ω—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞</b>\n\n"
        "–≠—Ç–æ—Ç –∞–∫–∫–∞—É–Ω—Ç –∑–∞–π–¥—ë—Ç –≤ –∫–∞–Ω–∞–ª—ã –∏ —Å–æ–±–µ—Ä—ë—Ç username.\n\n"
        "‚ö†Ô∏è –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π –∞–∫–∫–∞—É–Ω—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞, "
        "—á—Ç–æ–±—ã –Ω–µ –Ω–∞–≥—Ä—É–∂–∞—Ç—å —Ä–∞–±–æ—á–∏–µ –∞–∫–∫–∞—É–Ω—Ç—ã.",
        reply_markup=get_scraper_accounts_kb(accounts),
    )
    await callback.answer()


# =============================================================================
# Parallel Scraping Flow
# =============================================================================

@router.callback_query(F.data == "scraper:start_parallel")
async def start_parallel_scraping(
    callback: CallbackQuery,
    state: FSMContext,
    session: AsyncSession,
) -> None:
    """Start parallel scraping flow - multi-select accounts."""
    account_repo = PostgresAccountRepository(session)

    all_accounts = await account_repo.list_all(limit=100)
    accounts = [
        a for a in all_accounts
        if a.status in (AccountStatus.READY, AccountStatus.PAUSED, AccountStatus.ACTIVE)
        and a.session_data
    ]

    if len(accounts) < 2:
        await callback.message.edit_text(
            "‚ùå <b>–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∞–∫–∫–∞—É–Ω—Ç–æ–≤</b>\n\n"
            "–î–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 –∞–∫–∫–∞—É–Ω—Ç–∞.\n"
            f"–î–æ—Å—Ç—É–ø–Ω–æ: {len(accounts)}",
            reply_markup=get_scraper_menu_kb(),
        )
        await callback.answer()
        return

    await state.update_data(selected_accounts=[], parallel_mode=True)
    await state.set_state(ScraperStates.selecting_account)

    await callback.message.edit_text(
        "‚ö° <b>–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥</b>\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞.\n"
        "–ö–∞–Ω–∞–ª—ã –±—É–¥—É—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –º–µ–∂–¥—É –∞–∫–∫–∞—É–Ω—Ç–∞–º–∏.\n\n"
        f"üì± –î–æ—Å—Ç—É–ø–Ω–æ –∞–∫–∫–∞—É–Ω—Ç–æ–≤: {len(accounts)}",
        reply_markup=get_scraper_accounts_multi_kb(accounts, set()),
    )
    await callback.answer()


@router.callback_query(F.data.startswith("scraper:toggle:"), ScraperStates.selecting_account)
async def toggle_account_selection(
    callback: CallbackQuery,
    state: FSMContext,
    session: AsyncSession,
) -> None:
    """Toggle account selection for parallel scraping."""
    account_id = callback.data.split(":")[-1]

    data = await state.get_data()
    selected = set(data.get("selected_accounts", []))

    if account_id in selected:
        selected.discard(account_id)
    else:
        selected.add(account_id)

    await state.update_data(selected_accounts=list(selected))

    # Refresh keyboard
    account_repo = PostgresAccountRepository(session)
    all_accounts = await account_repo.list_all(limit=100)
    accounts = [
        a for a in all_accounts
        if a.status in (AccountStatus.READY, AccountStatus.PAUSED, AccountStatus.ACTIVE)
        and a.session_data
    ]

    await callback.message.edit_reply_markup(
        reply_markup=get_scraper_accounts_multi_kb(accounts, selected),
    )
    await callback.answer()


@router.callback_query(F.data == "scraper:select_all", ScraperStates.selecting_account)
async def select_all_accounts(
    callback: CallbackQuery,
    state: FSMContext,
    session: AsyncSession,
) -> None:
    """Select all accounts."""
    account_repo = PostgresAccountRepository(session)
    all_accounts = await account_repo.list_all(limit=100)
    accounts = [
        a for a in all_accounts
        if a.status in (AccountStatus.READY, AccountStatus.PAUSED, AccountStatus.ACTIVE)
        and a.session_data
    ]

    selected = {str(a.id) for a in accounts}
    await state.update_data(selected_accounts=list(selected))

    await callback.message.edit_reply_markup(
        reply_markup=get_scraper_accounts_multi_kb(accounts, selected),
    )
    await callback.answer(f"–í—ã–±—Ä–∞–Ω–æ {len(selected)} –∞–∫–∫–∞—É–Ω—Ç–æ–≤")


@router.callback_query(F.data == "scraper:select_none", ScraperStates.selecting_account)
async def select_no_accounts(
    callback: CallbackQuery,
    state: FSMContext,
    session: AsyncSession,
) -> None:
    """Deselect all accounts."""
    await state.update_data(selected_accounts=[])

    account_repo = PostgresAccountRepository(session)
    all_accounts = await account_repo.list_all(limit=100)
    accounts = [
        a for a in all_accounts
        if a.status in (AccountStatus.READY, AccountStatus.PAUSED, AccountStatus.ACTIVE)
        and a.session_data
    ]

    await callback.message.edit_reply_markup(
        reply_markup=get_scraper_accounts_multi_kb(accounts, set()),
    )
    await callback.answer("–í—ã–±–æ—Ä —Å–±—Ä–æ—à–µ–Ω")


@router.callback_query(F.data == "scraper:parallel:continue", ScraperStates.selecting_account)
async def parallel_continue_to_file(
    callback: CallbackQuery,
    state: FSMContext,
) -> None:
    """Continue to file upload for parallel scraping."""
    data = await state.get_data()
    selected = data.get("selected_accounts", [])

    if len(selected) < 2:
        await callback.answer("–í—ã–±–µ—Ä–∏—Ç–µ –º–∏–Ω–∏–º—É–º 2 –∞–∫–∫–∞—É–Ω—Ç–∞", show_alert=True)
        return

    await state.set_state(ScraperStates.waiting_channels_file)

    await callback.message.edit_text(
        f"‚ö° <b>–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥</b>\n\n"
        f"üì± –í—ã–±—Ä–∞–Ω–æ –∞–∫–∫–∞—É–Ω—Ç–æ–≤: {len(selected)}\n\n"
        "üìÅ <b>–û—Ç–ø—Ä–∞–≤—å—Ç–µ txt —Ñ–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –∫–∞–Ω–∞–ª–æ–≤</b>\n\n"
        "–ö–∞–Ω–∞–ª—ã –±—É–¥—É—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –º–µ–∂–¥—É –∞–∫–∫–∞—É–Ω—Ç–∞–º–∏.",
    )
    await callback.message.answer(
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ txt —Ñ–∞–π–ª:",
        reply_markup=get_cancel_kb(),
    )
    await callback.answer()


@router.callback_query(F.data.startswith("scraper:account:"), ScraperStates.selecting_account)
async def select_account(
    callback: CallbackQuery,
    state: FSMContext,
    session: AsyncSession,
) -> None:
    """Account selected - ask for channels file."""
    account_id = UUID(callback.data.split(":")[-1])

    account_repo = PostgresAccountRepository(session)
    account = await account_repo.get_by_id(account_id)

    if not account:
        await callback.answer("–ê–∫–∫–∞—É–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
        return

    await state.update_data(account_id=str(account_id))
    await state.set_state(ScraperStates.waiting_channels_file)

    await callback.message.edit_text(
        f"üì± –ê–∫–∫–∞—É–Ω—Ç: <b>{account.username or account.phone}</b>\n\n"
        "üìÅ <b>–û—Ç–ø—Ä–∞–≤—å—Ç–µ txt —Ñ–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –∫–∞–Ω–∞–ª–æ–≤</b>\n\n"
        "–§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ - –ø–æ –æ–¥–Ω–æ–π —Å—Å—ã–ª–∫–µ –Ω–∞ —Å—Ç—Ä–æ–∫—É:\n"
        "<code>https://t.me/channel1\n"
        "https://t.me/channel2\n"
        "@channel3</code>\n\n"
        "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç—ã:\n"
        "‚Ä¢ https://t.me/username\n"
        "‚Ä¢ t.me/username\n"
        "‚Ä¢ @username",
    )
    await callback.message.answer(
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ txt —Ñ–∞–π–ª:",
        reply_markup=get_cancel_kb(),
    )
    await callback.answer()


@router.message(ScraperStates.waiting_channels_file, F.document)
async def receive_channels_file(
    message: Message,
    state: FSMContext,
    session: AsyncSession,
) -> None:
    """Receive channels file and ask for campaign."""
    if not message.document.file_name.endswith(".txt"):
        await message.answer("‚ùå –û—Ç–ø—Ä–∞–≤—å—Ç–µ txt —Ñ–∞–π–ª")
        return

    # Download and parse file
    try:
        file = await message.bot.get_file(message.document.file_id)
        file_content = await message.bot.download_file(file.file_path)
        content = file_content.read().decode("utf-8")

        # Parse channels
        channels = []
        for line in content.strip().split("\n"):
            line = line.strip()
            if line and not line.startswith("#"):
                channels.append(line)

        if not channels:
            await message.answer("‚ùå –§–∞–π–ª –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Å—ã–ª–æ–∫")
            return

        await state.update_data(channels=channels)

        # Ask for campaign
        campaign_repo = PostgresCampaignRepository(session)
        campaigns = await campaign_repo.list_all(limit=50)

        await state.set_state(ScraperStates.selecting_campaign)

        await message.answer(
            f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∫–∞–Ω–∞–ª–æ–≤: <b>{len(channels)}</b>\n\n"
            "üì¢ <b>–ö—É–¥–∞ –¥–æ–±–∞–≤–∏—Ç—å —Å–æ–±—Ä–∞–Ω–Ω—ã–µ —Ç–∞—Ä–≥–µ—Ç—ã?</b>\n\n"
            "–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞–º–ø–∞–Ω–∏—é –∏–ª–∏ —Å–æ–±–µ—Ä–∏—Ç–µ –±–µ–∑ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –∫–∞–º–ø–∞–Ω–∏—é.",
            reply_markup=get_scraper_campaign_select_kb(campaigns),
        )

    except Exception as e:
        logger.error("Error parsing channels file", error=str(e))
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")


@router.callback_query(F.data.startswith("scraper:campaign:"), ScraperStates.selecting_campaign)
async def select_campaign_and_start(
    callback: CallbackQuery,
    state: FSMContext,
    session: AsyncSession,
) -> None:
    """Campaign selected - start scraping."""
    campaign_part = callback.data.split(":")[-1]
    campaign_id = None if campaign_part == "none" else UUID(campaign_part)

    data = await state.get_data()
    channels = data["channels"]
    parallel_mode = data.get("parallel_mode", False)
    selected_accounts = data.get("selected_accounts", [])

    account_repo = PostgresAccountRepository(session)

    if parallel_mode and len(selected_accounts) >= 2:
        # Parallel mode - multiple accounts
        accounts = []
        for acc_id_str in selected_accounts:
            acc = await account_repo.get_by_id(UUID(acc_id_str))
            if acc:
                accounts.append(acc)

        if len(accounts) < 2:
            await callback.answer("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤", show_alert=True)
            await state.clear()
            return

        # Create scrape task
        task = ScrapeTask(
            account_id=accounts[0].id,  # Primary account for tracking
            campaign_id=campaign_id,
            sources=channels,
        )

        await state.update_data(campaign_id=str(campaign_id) if campaign_id else None)
        await state.set_state(ScraperStates.scraping)

        # Show progress
        await callback.message.edit_text(
            "‚ö° <b>–ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞...</b>\n\n"
            f"üì± –ê–∫–∫–∞—É–Ω—Ç–æ–≤: {len(accounts)}\n"
            f"üìã –ö–∞–Ω–∞–ª–æ–≤: {len(channels)}\n"
            f"üì¢ –ö–∞–º–ø–∞–Ω–∏—è: {campaign_id or '–ë–µ–∑ –∫–∞–º–ø–∞–Ω–∏–∏'}\n\n"
            "‚è≥ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∞–∫–∫–∞—É–Ω—Ç–æ–≤...",
            reply_markup=get_scraper_progress_kb(str(task.id)),
        )
        await callback.answer()

        # Run parallel scraping in background
        user_id = callback.from_user.id
        asyncio.create_task(
            _run_parallel_scraping(
                user_id=user_id,
                accounts=accounts,
                task=task,
                message=callback.message,
                state=state,
            )
        )
    else:
        # Single account mode
        account_id = UUID(data["account_id"])
        account = await account_repo.get_by_id(account_id)

        if not account:
            await callback.answer("–ê–∫–∫–∞—É–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
            await state.clear()
            return

        # Create scrape task
        task = ScrapeTask(
            account_id=account_id,
            campaign_id=campaign_id,
            sources=channels,
        )

        await state.update_data(campaign_id=str(campaign_id) if campaign_id else None)
        await state.set_state(ScraperStates.scraping)

        # Show progress
        await callback.message.edit_text(
            "üîç <b>–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞...</b>\n\n"
            f"üì± –ê–∫–∫–∞—É–Ω—Ç: {account.username or account.phone}\n"
            f"üìã –ö–∞–Ω–∞–ª–æ–≤: {len(channels)}\n"
            f"üì¢ –ö–∞–º–ø–∞–Ω–∏—è: {campaign_id or '–ë–µ–∑ –∫–∞–º–ø–∞–Ω–∏–∏'}\n\n"
            "‚è≥ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...",
            reply_markup=get_scraper_progress_kb(str(task.id)),
        )
        await callback.answer()

        # Run scraping in background
        user_id = callback.from_user.id
        asyncio.create_task(
            _run_scraping(
                user_id=user_id,
                account=account,
                task=task,
                message=callback.message,
                state=state,
                session_factory=session,
            )
        )


async def _run_scraping(
    user_id: int,
    account: Account,
    task: ScrapeTask,
    message: Message,
    state: FSMContext,
    session_factory,
) -> None:
    """Run scraping in background."""
    scraper = None
    try:
        # Load existing usernames from DB to avoid duplicates
        from src.infrastructure.database import get_session
        existing_usernames: set[str] = set()

        async with get_session() as session:
            target_repo = PostgresUserTargetRepository(session)
            existing_usernames = await target_repo.get_all_existing_usernames()
            logger.info(
                "Loaded existing usernames for deduplication",
                count=len(existing_usernames),
            )

        # Create progress callback
        async def update_progress(t: ScrapeTask):
            try:
                progress_text = (
                    f"üîç <b>–ü–∞—Ä—Å–∏–Ω–≥...</b>\n\n"
                    f"üì± –ê–∫–∫–∞—É–Ω—Ç: {account.username or account.phone}\n"
                    f"üìã –ü—Ä–æ–≥—Ä–µ—Å—Å: {t.processed_sources}/{t.total_sources}\n"
                    f"üë• –ù–∞–π–¥–µ–Ω–æ: {len(t.collected_usernames)}\n"
                    f"üö´ –í –±–∞–∑–µ: {len(existing_usernames)} (–ø—Ä–æ–ø—É—Å–∫–∞—é—Ç—Å—è)\n"
                )
                if t.current_source:
                    progress_text += f"üîÑ –¢–µ–∫—É—â–∏–π: {t.current_source[:30]}...\n"

                await message.edit_text(
                    progress_text,
                    reply_markup=get_scraper_progress_kb(str(t.id)),
                )
            except Exception:
                pass

        # Start scraper with existing usernames for filtering
        scraper = ScraperService(
            account=account,
            on_progress=lambda t: asyncio.create_task(update_progress(t)),
            existing_usernames=existing_usernames,
        )
        _active_scrapers[user_id] = scraper
        _active_tasks[user_id] = task

        await scraper.start()

        # Run scraping
        task = await scraper.run_scrape_task(task)

        # Save targets to campaign if specified
        from src.infrastructure.database import get_session
        import io
        from aiogram.types import BufferedInputFile

        async with get_session() as session:
            if task.campaign_id and task.collected_usernames:
                target_repo = PostgresUserTargetRepository(session)

                # Check for existing usernames
                existing = set()
                for username in task.collected_usernames:
                    existing_target = await target_repo.get_by_username(
                        task.campaign_id, username
                    )
                    if existing_target:
                        existing.add(username)

                # Create new targets
                new_usernames = [u for u in task.collected_usernames if u not in existing]
                targets = create_targets_from_usernames(
                    usernames=new_usernames,
                    campaign_id=task.campaign_id,
                    source="scraper",
                )

                for target in targets:
                    await target_repo.save(target)

                await session.commit()

                task.users_added = len(targets)
                task.users_skipped = len(existing)

        # Show results
        result_text = (
            f"‚úÖ <b>–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω!</b>\n\n"
            f"üìã –ö–∞–Ω–∞–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {task.processed_sources}/{task.total_sources}\n"
            f"üë• –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {len(task.collected_usernames)}\n"
        )

        if task.campaign_id:
            result_text += (
                f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –∫–∞–º–ø–∞–Ω–∏—é: {task.users_added}\n"
                f"‚è≠ –ü—Ä–æ–ø—É—â–µ–Ω–æ (–¥—É–±–ª–∏): {task.users_skipped}\n"
            )

        if task.failed_sources:
            result_text += f"\n‚ö†Ô∏è –û—à–∏–±–æ–∫: {len(task.failed_sources)}"

        try:
            await message.edit_text(
                result_text,
                reply_markup=get_scraper_result_kb(task.campaign_id),
            )
        except Exception as edit_err:
            logger.warning("Failed to edit message with results", error=str(edit_err))
            # Try sending new message instead
            await message.answer(result_text, reply_markup=get_scraper_result_kb(task.campaign_id))

        # Send txt file with usernames if no campaign selected
        if not task.campaign_id and task.collected_usernames:
            file_content = "\n".join(task.collected_usernames)
            file_bytes = file_content.encode("utf-8")
            input_file = BufferedInputFile(
                file_bytes,
                filename=f"usernames_{len(task.collected_usernames)}.txt",
            )
            await message.answer_document(
                input_file,
                caption=f"üìÑ –°–æ–±—Ä–∞–Ω–Ω—ã–µ username ({len(task.collected_usernames)} —à—Ç.)",
            )

    except Exception as e:
        logger.error("Scraping failed", error=str(e), exc_info=True)
        try:
            await message.edit_text(
                f"‚ùå <b>–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞</b>\n\n{str(e)[:200]}",
                reply_markup=get_scraper_menu_kb(),
            )
        except Exception:
            await message.answer(
                f"‚ùå <b>–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞</b>\n\n{str(e)[:200]}",
                reply_markup=get_scraper_menu_kb(),
            )

    finally:
        # Cleanup
        if scraper:
            await scraper.stop()
        _active_scrapers.pop(user_id, None)
        _active_tasks.pop(user_id, None)
        await state.clear()


async def _run_parallel_scraping(
    user_id: int,
    accounts: list[Account],
    task: ScrapeTask,
    message: Message,
    state: FSMContext,
) -> None:
    """Run parallel scraping with multiple accounts."""
    scraper = None
    try:
        # Load existing usernames from DB
        from src.infrastructure.database import get_session
        import io
        from aiogram.types import BufferedInputFile

        existing_usernames: set[str] = set()
        async with get_session() as session:
            target_repo = PostgresUserTargetRepository(session)
            existing_usernames = await target_repo.get_all_existing_usernames()
            logger.info(
                "Parallel: Loaded existing usernames",
                count=len(existing_usernames),
            )

        # Progress callback
        async def update_progress(t: ScrapeTask):
            try:
                progress_text = (
                    f"‚ö° <b>–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥...</b>\n\n"
                    f"üì± –ê–∫–∫–∞—É–Ω—Ç–æ–≤: {len(accounts)}\n"
                    f"üìã –ü—Ä–æ–≥—Ä–µ—Å—Å: {t.processed_sources}/{t.total_sources}\n"
                    f"üë• –ù–∞–π–¥–µ–Ω–æ: {len(t.collected_usernames)}\n"
                    f"üö´ –í –±–∞–∑–µ: {len(existing_usernames)} (–ø—Ä–æ–ø—É—Å–∫–∞—é—Ç—Å—è)\n"
                )
                if t.current_source:
                    progress_text += f"üîÑ –¢–µ–∫—É—â–∏–π: {t.current_source[:30]}...\n"

                await message.edit_text(
                    progress_text,
                    reply_markup=get_scraper_progress_kb(str(t.id)),
                )
            except Exception:
                pass

        # Create parallel scraper
        scraper = ParallelScraperService(
            accounts=accounts,
            on_progress=lambda t: asyncio.create_task(update_progress(t)),
            existing_usernames=existing_usernames,
        )
        _active_parallel_scrapers[user_id] = scraper
        _active_tasks[user_id] = task

        # Connect all accounts
        connected = await scraper.start()
        logger.info("Parallel scraper: connected accounts", count=connected)

        if connected < 2:
            await message.edit_text(
                f"‚ùå <b>–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∞–∫–∫–∞—É–Ω—Ç–æ–≤</b>\n\n"
                f"–ü–æ–¥–∫–ª—é—á–µ–Ω–æ —Ç–æ–ª—å–∫–æ {connected} –∏–∑ {len(accounts)}",
                reply_markup=get_scraper_menu_kb(),
            )
            return

        # Run scraping
        task = await scraper.run_scrape_task(task)

        # Save targets to campaign if specified
        async with get_session() as session:
            if task.campaign_id and task.collected_usernames:
                target_repo = PostgresUserTargetRepository(session)

                existing = await target_repo.get_existing_usernames(
                    list(task.collected_usernames),
                    task.campaign_id,
                )

                new_usernames = [u for u in task.collected_usernames if u not in existing]
                targets = create_targets_from_usernames(
                    usernames=new_usernames,
                    campaign_id=task.campaign_id,
                    source="parallel_scraper",
                )

                for target in targets:
                    await target_repo.save(target)

                await session.commit()

                task.users_added = len(targets)
                task.users_skipped = len(existing)

        # Show results
        result_text = (
            f"‚úÖ <b>–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω!</b>\n\n"
            f"üì± –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∞–∫–∫–∞—É–Ω—Ç–æ–≤: {len(accounts)}\n"
            f"üìã –ö–∞–Ω–∞–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {task.processed_sources}/{task.total_sources}\n"
            f"üë• –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {len(task.collected_usernames)}\n"
        )

        if task.campaign_id:
            result_text += (
                f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –∫–∞–º–ø–∞–Ω–∏—é: {task.users_added}\n"
                f"‚è≠ –ü—Ä–æ–ø—É—â–µ–Ω–æ (–¥—É–±–ª–∏): {task.users_skipped}\n"
            )

        if task.failed_sources:
            result_text += f"\n‚ö†Ô∏è –û—à–∏–±–æ–∫: {len(task.failed_sources)}"

        try:
            await message.edit_text(
                result_text,
                reply_markup=get_scraper_result_kb(task.campaign_id),
            )
        except Exception:
            await message.answer(result_text, reply_markup=get_scraper_result_kb(task.campaign_id))

        # Send txt file if no campaign
        if not task.campaign_id and task.collected_usernames:
            file_content = "\n".join(task.collected_usernames)
            file_bytes = file_content.encode("utf-8")
            input_file = BufferedInputFile(
                file_bytes,
                filename=f"usernames_{len(task.collected_usernames)}.txt",
            )
            await message.answer_document(
                input_file,
                caption=f"üìÑ –°–æ–±—Ä–∞–Ω–Ω—ã–µ username ({len(task.collected_usernames)} —à—Ç.)",
            )

    except Exception as e:
        logger.error("Parallel scraping failed", error=str(e), exc_info=True)
        try:
            await message.edit_text(
                f"‚ùå <b>–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞</b>\n\n{str(e)[:200]}",
                reply_markup=get_scraper_menu_kb(),
            )
        except Exception:
            await message.answer(
                f"‚ùå <b>–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞</b>\n\n{str(e)[:200]}",
                reply_markup=get_scraper_menu_kb(),
            )

    finally:
        if scraper:
            await scraper.stop()
        _active_parallel_scrapers.pop(user_id, None)
        _active_tasks.pop(user_id, None)
        await state.clear()


# =============================================================================
# Cancel / Stop
# =============================================================================

@router.callback_query(F.data == "scraper:cancel")
async def cancel_scraping(callback: CallbackQuery, state: FSMContext) -> None:
    """Cancel scraping flow."""
    user_id = callback.from_user.id

    # Stop active scraper if any
    scraper = _active_scrapers.get(user_id)
    if scraper:
        scraper.cancel()

    parallel_scraper = _active_parallel_scrapers.get(user_id)
    if parallel_scraper:
        parallel_scraper.cancel()

    await state.clear()
    await callback.message.edit_text(
        "‚ùå –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–º–µ–Ω—ë–Ω",
        reply_markup=get_scraper_menu_kb(),
    )
    await callback.answer()


@router.callback_query(F.data.startswith("scraper:stop:"))
async def stop_scraping(callback: CallbackQuery, state: FSMContext) -> None:
    """Stop active scraping."""
    user_id = callback.from_user.id

    scraper = _active_scrapers.get(user_id)
    parallel_scraper = _active_parallel_scrapers.get(user_id)

    if scraper:
        scraper.cancel()
        await callback.answer("–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º...")
    elif parallel_scraper:
        parallel_scraper.cancel()
        await callback.answer("–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥...")
    else:
        await callback.answer("–ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ –∑–∞–ø—É—â–µ–Ω", show_alert=True)


@router.message(F.text == "‚ùå –û—Ç–º–µ–Ω–∞", ScraperStates)
async def cancel_scraping_text(message: Message, state: FSMContext) -> None:
    """Cancel via text button."""
    user_id = message.from_user.id

    scraper = _active_scrapers.get(user_id)
    if scraper:
        scraper.cancel()

    await state.clear()
    await message.answer(
        "‚ùå –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–º–µ–Ω—ë–Ω",
        reply_markup=get_main_menu_kb(),
    )
